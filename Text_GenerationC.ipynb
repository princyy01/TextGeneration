{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXBWTTz7f16P"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWJeVF8bgKlS",
        "outputId": "42c59601-d5b8-4437-b40d-a6210897e270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the RNN model\n",
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "        super(CharRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input)\n",
        "        output, hidden = self.lstm(embedded, hidden)\n",
        "        output = self.fc(output[:, -1, :])\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device),\n",
        "                torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device))"
      ],
      "metadata": {
        "id": "KUn7_K7TgVcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the input text\n",
        "def preprocess(text):\n",
        "    chars = list(set(text))\n",
        "    char_to_index = {char: i for i, char in enumerate(chars)}\n",
        "    index_to_char = {i: char for i, char in enumerate(chars)}\n",
        "    return chars, char_to_index, index_to_char"
      ],
      "metadata": {
        "id": "i-lq8lKcgW1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate training data\n",
        "def generate_training_data(text, seq_length):\n",
        "    input_seqs = []\n",
        "    target_seqs = []\n",
        "    for i in range(len(text) - seq_length):\n",
        "        input_seq = text[i:i+seq_length]\n",
        "        target_seq = text[i+seq_length]\n",
        "        input_seqs.append([char_to_index[char] for char in input_seq])\n",
        "        target_seqs.append(char_to_index[target_seq])\n",
        "    return input_seqs, target_seqs"
      ],
      "metadata": {
        "id": "I5P87dqGgZ5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "seq_length = 100\n",
        "hidden_size = 256\n",
        "num_layers = 2\n",
        "learning_rate = 0.001\n",
        "num_epochs = 50\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "xJWe6abUgdJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the input text\n",
        "filename = \"Deep Learning.txt\"\n",
        "text = open(filename, 'r', encoding='utf-8').read()\n",
        "chars, char_to_index, index_to_char = preprocess(text)\n",
        "input_seqs, target_seqs = generate_training_data(text, seq_length)"
      ],
      "metadata": {
        "id": "qF8j_lOoggJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to PyTorch tensors\n",
        "input_seqs = torch.tensor(input_seqs, dtype=torch.long).to(device)\n",
        "target_seqs = torch.tensor(target_seqs, dtype=torch.long).to(device)\n",
        "\n",
        "# Define input and output sizes based on the processed text\n",
        "input_size = len(chars)\n",
        "output_size = len(chars)"
      ],
      "metadata": {
        "id": "AYHcdBSLgizj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = CharRNN(input_size, hidden_size, output_size, num_layers).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "P8HcsyM8gmq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "total_batches = len(input_seqs) // batch_size\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "\n",
        "    # Shuffle the data\n",
        "    indices = torch.randperm(len(input_seqs))\n",
        "    input_seqs = input_seqs[indices]\n",
        "    target_seqs = target_seqs[indices]\n",
        "\n",
        "    # Mini-batch training\n",
        "    for batch in range(total_batches):\n",
        "        start_idx = batch * batch_size\n",
        "        end_idx = start_idx + batch_size\n",
        "        input_batch = input_seqs[start_idx:end_idx]\n",
        "        target_batch = target_seqs[start_idx:end_idx]\n",
        "\n",
        "        hidden = model.init_hidden(input_batch.size(0))\n",
        "        hidden = tuple(tensor.to(device) for tensor in hidden)\n",
        "\n",
        "        # Forward pass\n",
        "        output, hidden = model(input_batch, hidden)\n",
        "        loss = criterion(output, target_batch)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print the loss every 5 epochs till 50\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        average_loss = running_loss / total_batches\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-V74mq0gsYe",
        "outputId": "3a304957-0d4e-41cc-e3ef-b14803078016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/50], Loss: 1.0369\n",
            "Epoch [10/50], Loss: 0.6060\n",
            "Epoch [15/50], Loss: 0.3636\n",
            "Epoch [20/50], Loss: 0.2150\n",
            "Epoch [25/50], Loss: 0.1355\n",
            "Epoch [30/50], Loss: 0.0995\n",
            "Epoch [35/50], Loss: 0.1025\n",
            "Epoch [40/50], Loss: 0.0490\n",
            "Epoch [45/50], Loss: 0.0305\n",
            "Epoch [50/50], Loss: 0.0141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text\n",
        "model.eval()\n",
        "# Generate text\n",
        "model.eval()\n",
        "sentence_end_markers = ['.', '?']  # Add other sentence end markers if needed\n",
        "end_indices = [i for i, char in enumerate(text) if char in sentence_end_markers]\n",
        "start = np.random.choice(end_indices) + 1  # Add 1 to start at the next character\n",
        "start_seq = text[start:start+seq_length]\n",
        "generated_text = start_seq\n",
        "\n",
        "with torch.no_grad():\n",
        "    hidden = model.init_hidden(1)\n",
        "    hidden = tuple(tensor.to(device) for tensor in hidden)\n",
        "\n",
        "    input_seq = torch.tensor([char_to_index[char] for char in start_seq], dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    num_words = len(generated_text.split())\n",
        "\n",
        "    while num_words < 100 or not generated_text.endswith((\".\", \"!\", \"?\")):\n",
        "        output, hidden = model(input_seq, hidden)\n",
        "        probabilities = nn.functional.softmax(output, dim=1).squeeze().cpu().numpy()\n",
        "        predicted_index = np.random.choice(len(chars), p=probabilities)\n",
        "        predicted_char = index_to_char[predicted_index]\n",
        "        generated_text += predicted_char\n",
        "        input_seq = torch.tensor([[predicted_index]], dtype=torch.long).to(device)\n",
        "\n",
        "        # Update the word count\n",
        "        num_words = len(generated_text.split())\n",
        "\n",
        "print(\"Generated Text:\")\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOsR-x6oh5UH",
        "outputId": "9657b1bf-4168-4d5d-d30a-bb6be2079ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            " Recommender systems employ Deep Learning architectures to provide personalized recommendations to users, enhancing user experiences and improving direas are black boxes, understanding how they arrive at their predictions or decisions can be challenging. Researchers are working towards a crural language processing, and various domains and unleashing new possibilities for solving complex real-world problems.\n",
            "\n",
            "Furthermore, the future of Deep Learning holds immense potential. Researchers are exploring novel approaches such as recommender systems, fraud detection, custome shing orgation and data and chatbot development. With the field of Deep Learning with other fields such as reinforcement learning, and attention mechanisms to further enhance the capabilities of Deep Learning technologies are paramount and society as a whole.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wZHefgLFiHQH",
        "outputId": "f40bf2a5-9c38-40cb-f1ec-afc41b17c6d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Recommender systems employ Deep Learning architectures to provide personalized recommendations to u'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}